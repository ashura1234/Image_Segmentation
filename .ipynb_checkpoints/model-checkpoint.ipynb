{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "import PIL\n",
    "import cv2\n",
    "import csv\n",
    "import os\n",
    "import glob\n",
    "import time\n",
    "import copy\n",
    "\n",
    "\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets, transforms, models\n",
    "from torchvision.models.segmentation.deeplabv3 import DeepLabHead\n",
    "from sklearn.metrics import roc_auc_score, f1_score\n",
    "from torchsummary import summary\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "894\n"
     ]
    }
   ],
   "source": [
    "label_map = {}\n",
    "i = 0\n",
    "with open('data/labelNames.csv', newline='') as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter=',',)\n",
    "    for row in reader:\n",
    "        if i > 0 :\n",
    "            label_map[row[0]] = row[1]\n",
    "        i += 1\n",
    "print(len(label_map))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Normalize(object):\n",
    "    '''Normalize image'''\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, label = sample['image'], sample['label']\n",
    "        return {'image': image.type(torch.FloatTensor)/255,\n",
    "                \n",
    "                #*********************************************************************\n",
    "                #This is definetely wrong\n",
    "                #Label is a 1 channel uint8 tensor labeling all pixels\n",
    "                #This is just force it be a float tensor\n",
    "                \n",
    "                #In the example code, it uses a binary mask\n",
    "                #The NYU datasets does include binary masks for all classes\n",
    "                #I'm not sure if I should use a single channel label image or\n",
    "                #a 3-dimentional HxWx(# of classes) mask as the ground truth\n",
    "                #*********************************************************************\n",
    "                'label': label#.type(torch.FloatTensor)/len(label_map)\n",
    "               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SegDataset(Dataset):\n",
    "    \"\"\"Segmentation Dataset\"\"\"\n",
    "\n",
    "    def __init__(self, root_dir, imageFolder, labelFolder, transform=None, \n",
    "                 seed=None, fraction=None, subset=None, imagecolormode='rgb', labelcolormode='grayscale'):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root_dir (string): Directory with all the images and should have the following structure.\n",
    "            root\n",
    "            --Images\n",
    "            -----image00001\n",
    "            -----image__N__\n",
    "            --Label\n",
    "            -----label00001\n",
    "            -----label__N__\n",
    "            imageFolder (string) = 'Images' : Name of the folder which contains the Images.\n",
    "            labelFolder (string)  = 'Labels : Name of the folder which contains the Labels.\n",
    "            transform (callable, optional): Optional transform to be applied on a sample.\n",
    "            seed: Specify a seed for the train and test split\n",
    "            fraction: A float value from 0 to 1 which specifies the validation split fraction\n",
    "            subset: 'Train' or 'Test' to select the appropriate set.\n",
    "            imagecolormode: 'rgb' or 'grayscale'\n",
    "            labelcolormode: 'rgb' or 'grayscale'\n",
    "        \"\"\"\n",
    "        self.color_dict = {'rgb': 1, 'grayscale': 0}\n",
    "        assert(imagecolormode in ['rgb', 'grayscale'])\n",
    "        assert(labelcolormode in ['rgb', 'grayscale'])\n",
    "\n",
    "        self.imagecolorflag = self.color_dict[imagecolormode]\n",
    "        self.labelcolorflag = self.color_dict[labelcolormode]\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        if not fraction:\n",
    "            self.image_names = sorted(\n",
    "                glob.glob(os.path.join(self.root_dir, imageFolder, '*')))\n",
    "            self.label_names = sorted(\n",
    "                glob.glob(os.path.join(self.root_dir, labelFolder, '*')))\n",
    "        else:\n",
    "            assert(subset in ['Train', 'Test'])\n",
    "            self.fraction = fraction\n",
    "            self.image_list = np.array(\n",
    "                sorted(glob.glob(os.path.join(self.root_dir, imageFolder, '*'))))\n",
    "            self.label_list = np.array(\n",
    "                sorted(glob.glob(os.path.join(self.root_dir, labelFolder, '*'))))\n",
    "            if seed:\n",
    "                np.random.seed(seed)\n",
    "                indices = np.arange(len(self.image_list))\n",
    "                np.random.shuffle(indices)\n",
    "                self.image_list = self.image_list[indices]\n",
    "                self.label_list = self.label_list[indices]\n",
    "            if subset == 'Train':\n",
    "                self.image_names = self.image_list[:int(\n",
    "                    np.ceil(len(self.image_list)*(1-self.fraction)))]\n",
    "                self.label_names = self.label_list[:int(\n",
    "                    np.ceil(len(self.label_list)*(1-self.fraction)))]\n",
    "            else:\n",
    "                self.image_names = self.image_list[int(\n",
    "                    np.ceil(len(self.image_list)*(1-self.fraction))):]\n",
    "                self.label_names = self.label_list[int(\n",
    "                    np.ceil(len(self.label_list)*(1-self.fraction))):]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_names)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.image_names[idx]\n",
    "        if self.imagecolorflag:\n",
    "            image = cv2.imread(\n",
    "                img_name, self.imagecolorflag).transpose(2, 0, 1)\n",
    "        else:\n",
    "            image = cv2.imread(img_name, self.imagecolorflag)\n",
    "        lbl_name = self.label_names[idx]\n",
    "        if self.labelcolorflag:\n",
    "            label = cv2.imread(lbl_name, self.labelcolorflag).transpose(2, 0, 1)\n",
    "        else:\n",
    "            label = cv2.imread(lbl_name, self.labelcolorflag)\n",
    "        sample = {'image': image, 'label': label}\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToTensor(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "\n",
    "    def __call__(self, sample, labelresize=None, imageresize=None):\n",
    "        image, label = sample['image'], sample['label']\n",
    "        if len(label.shape) == 2:\n",
    "            label = label.reshape((1,)+label.shape)\n",
    "        if len(image.shape) == 2:\n",
    "            image = image.reshape((1,)+image.shape)\n",
    "        return {'image': torch.from_numpy(image),\n",
    "                'label': torch.from_numpy(label)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloader_sep_folder(data_dir, imageFolder='data/Train/Image', labelFolder='data/Train/Label', batch_size=4):\n",
    "    \"\"\"\n",
    "        Create Train and Test dataloaders from two separate Train and Test folders.\n",
    "        The directory structure should be as follows.\n",
    "        data_dir\n",
    "        --Train\n",
    "        ------Image\n",
    "        ---------image00001\n",
    "        ---------image__N__\n",
    "        ------Label\n",
    "        ---------label00001\n",
    "        ---------label__N__\n",
    "        --Test\n",
    "        ------Image\n",
    "        ---------image00001\n",
    "        ---------image__N__\n",
    "        ------Label\n",
    "        ---------label00001\n",
    "        ---------label__N__\n",
    "    \"\"\"\n",
    "    data_transforms = {\n",
    "        'Train': transforms.Compose([ToTensor(), Normalize()]),\n",
    "        'Test': transforms.Compose([ToTensor(), Normalize()]),\n",
    "    }\n",
    "\n",
    "    image_datasets = {x: SegDataset(root_dir=os.path.join(data_dir, x),\n",
    "                                    transform=data_transforms[x], labelFolder=labelFolder, imageFolder=imageFolder)\n",
    "                      for x in ['Train', 'Test']}\n",
    "    dataloaders = {x: DataLoader(image_datasets[x], batch_size=batch_size,\n",
    "                                 shuffle=True, num_workers=8)\n",
    "                   for x in ['Train', 'Test']}\n",
    "    return dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def im_convert(tensor):\n",
    "    image = tensor.cpu().clone().detach().numpy()\n",
    "    image = image.transpose(1, 2, 0)\n",
    "    image = image * np.array((0.5, 0.5, 0.5)) + np.array((0.5, 0.5, 0.5))\n",
    "    image = image.clip(0, 1)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeepLabV3(\n",
       "  (backbone): IntermediateLayerGetter(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (6): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (7): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (8): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (9): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (10): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (11): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (12): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (13): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (14): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (15): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (16): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (17): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (18): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (19): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (20): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (21): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (22): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): DeepLabHead(\n",
       "    (0): ASPP(\n",
       "      (convs): ModuleList(\n",
       "        (0): Sequential(\n",
       "          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (1): ASPPConv(\n",
       "          (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (2): ASPPConv(\n",
       "          (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(24, 24), dilation=(24, 24), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (3): ASPPConv(\n",
       "          (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(36, 36), dilation=(36, 36), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU()\n",
       "        )\n",
       "        (4): ASPPPooling(\n",
       "          (0): AdaptiveAvgPool2d(output_size=1)\n",
       "          (1): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (3): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (project): Sequential(\n",
       "        (0): Conv2d(1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Dropout(p=0.5, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): ReLU()\n",
       "    (4): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (aux_classifier): FCNHead(\n",
       "    (0): Conv2d(1024, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Dropout(p=0.1, inplace=False)\n",
       "    (4): Conv2d(256, 21, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def createDeepLabv3(outputchannels=1):\n",
    "    model = models.segmentation.deeplabv3_resnet101(\n",
    "        pretrained=True, progress=True)\n",
    "    #summary(model.cuda().classifier,(2048, 80, 60))\n",
    "    \n",
    "    #*********************************************************************\n",
    "    #It seems like the example uses it to replace the classification part of model.\n",
    "    #*********************************************************************\n",
    "    # Added a Sigmoid activation after the last convolution layer\n",
    "    model.classifier = DeepLabHead(2048, outputchannels)\n",
    "    #summary(model.cuda().classifier,(2048, 80, 60))\n",
    "    # Set the model in training mode\n",
    "    model.train()\n",
    "    return model\n",
    "createDeepLabv3(outputchannels=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, dataloaders, optimizer, metrics, bpath, num_epochs=3):\n",
    "    since = time.time()\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_loss = 1e10\n",
    "    # Initialize the log file for training and testing loss and metrics\n",
    "    fieldnames = ['epoch', 'Train_loss', 'Test_loss'] + \\\n",
    "        [f'Train_{m}' for m in metrics.keys()] + \\\n",
    "        [f'Test_{m}' for m in metrics.keys()]\n",
    "#     with open(os.path.join(bpath, 'log.csv'), 'w', newline='') as csvfile:\n",
    "#         writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "#         writer.writeheader()\n",
    "\n",
    "    for epoch in range(1, num_epochs+1):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs))\n",
    "        print('-' * 10)\n",
    "        # Each epoch has a training and validation phase\n",
    "        # Initialize batch summary\n",
    "        batchsummary = {a: [0] for a in fieldnames}\n",
    "\n",
    "        for phase in ['Train', 'Test']:\n",
    "            if phase == 'Train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            # Iterate over data.\n",
    "            for sample in tqdm(iter(dataloaders[phase])):\n",
    "                inputs = sample['image'].to(device)\n",
    "                labels = sample['label'].to(device)\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'Train'):\n",
    "                    outputs = model(inputs)\n",
    "                    \n",
    "                    #*********************************************************************\n",
    "                    #outputs is a [-1, 1, 80, 60] float tensor. See the last cell.\n",
    "                    #But out labels are uint8 tensors.\n",
    "                    #Should apply some kind of softmax or classification?\n",
    "                    #Should I transform the label to be a (# of classes)x640x480 tensor?\n",
    "                    #*********************************************************************\n",
    "                    \n",
    "                    loss = criterion(outputs['out'], labels)\n",
    "#                     y_pred = outputs['out'].data.cpu().numpy().ravel()\n",
    "#                     y_true = labels.data.cpu().numpy().ravel()\n",
    "#                     for name, metric in metrics.items():\n",
    "#                         if name == 'f1_score':\n",
    "#                             # Use a classification threshold of 0.1\n",
    "#                             batchsummary[f'{phase}_{name}'].append(\n",
    "#                                 metric(y_true > 0, y_pred > 0.1))\n",
    "#                         else:\n",
    "#                             batchsummary[f'{phase}_{name}'].append(\n",
    "#                                 metric(y_true.astype('uint8'), y_pred))\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'Train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "            batchsummary['epoch'] = epoch\n",
    "            epoch_loss = loss\n",
    "            batchsummary[f'{phase}_loss'] = epoch_loss.item()\n",
    "            print('{} Loss: {:.4f}'.format(\n",
    "                phase, loss))\n",
    "        for field in fieldnames[3:]:\n",
    "            batchsummary[field] = np.mean(batchsummary[field])\n",
    "        print(batchsummary)\n",
    "        with open(os.path.join(bpath, 'log.csv'), 'a', newline='') as csvfile:\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "            writer.writerow(batchsummary)\n",
    "            # deep copy the model\n",
    "            if phase == 'Test' and loss < best_loss:\n",
    "                best_loss = loss\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Lowest Loss: {:4f}'.format(best_loss))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpath = 'data/Output'\n",
    "data_dir = 'data'\n",
    "image_dir = 'Image/1'\n",
    "label_dir = 'Label/1'\n",
    "epochs = 3\n",
    "\n",
    "#Due to GPU memory limitation\n",
    "batchsize = 2\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Create the deeplabv3 resnet101 model which is pretrained on a subset of COCO train2017, on the 20 categories that are present in the Pascal VOC dataset.\n",
    "model = createDeepLabv3().to(device)\n",
    "# summary(model.backbone, (3, 640, 480))\n",
    "# Create the experiment directory if not present\n",
    "if not os.path.isdir(bpath):\n",
    "    os.mkdir(bpath)\n",
    "\n",
    "# Specify the loss function\n",
    "\n",
    "#**********************************************************************************\n",
    "#Loss function was MSELoss, I changed to cross entropy for classification problems.\n",
    "#**********************************************************************************\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "# Specify the optimizer with a lower learning rate\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "#**********************************************************************************\n",
    "#I understand metrics are for tuning hyperparameters but I don't really know how to use it.\n",
    "#**********************************************************************************\n",
    "metrics = {'auroc': roc_auc_score} #'f1_score': f1_score, \n",
    "dataloaders = get_dataloader_sep_folder(data_dir, imageFolder=image_dir, labelFolder=label_dir, batch_size=batchsize)\n",
    "trained_model = train_model(model, criterion, dataloaders,\n",
    "                            optimizer, bpath=bpath, metrics=metrics, num_epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving/loading the trained models\n",
    "\n",
    "# savepath='data/Output/checkpoint.pth'\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# #torch.save(model.state_dict(), savepath)\n",
    "# model = createDeepLabv3().to(device)\n",
    "# model.load_state_dict(torch.load(savepath))\n",
    "# #model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 320, 240]           9,408\n",
      "       BatchNorm2d-2         [-1, 64, 320, 240]             128\n",
      "              ReLU-3         [-1, 64, 320, 240]               0\n",
      "         MaxPool2d-4         [-1, 64, 160, 120]               0\n",
      "            Conv2d-5         [-1, 64, 160, 120]           4,096\n",
      "       BatchNorm2d-6         [-1, 64, 160, 120]             128\n",
      "              ReLU-7         [-1, 64, 160, 120]               0\n",
      "            Conv2d-8         [-1, 64, 160, 120]          36,864\n",
      "       BatchNorm2d-9         [-1, 64, 160, 120]             128\n",
      "             ReLU-10         [-1, 64, 160, 120]               0\n",
      "           Conv2d-11        [-1, 256, 160, 120]          16,384\n",
      "      BatchNorm2d-12        [-1, 256, 160, 120]             512\n",
      "           Conv2d-13        [-1, 256, 160, 120]          16,384\n",
      "      BatchNorm2d-14        [-1, 256, 160, 120]             512\n",
      "             ReLU-15        [-1, 256, 160, 120]               0\n",
      "       Bottleneck-16        [-1, 256, 160, 120]               0\n",
      "           Conv2d-17         [-1, 64, 160, 120]          16,384\n",
      "      BatchNorm2d-18         [-1, 64, 160, 120]             128\n",
      "             ReLU-19         [-1, 64, 160, 120]               0\n",
      "           Conv2d-20         [-1, 64, 160, 120]          36,864\n",
      "      BatchNorm2d-21         [-1, 64, 160, 120]             128\n",
      "             ReLU-22         [-1, 64, 160, 120]               0\n",
      "           Conv2d-23        [-1, 256, 160, 120]          16,384\n",
      "      BatchNorm2d-24        [-1, 256, 160, 120]             512\n",
      "             ReLU-25        [-1, 256, 160, 120]               0\n",
      "       Bottleneck-26        [-1, 256, 160, 120]               0\n",
      "           Conv2d-27         [-1, 64, 160, 120]          16,384\n",
      "      BatchNorm2d-28         [-1, 64, 160, 120]             128\n",
      "             ReLU-29         [-1, 64, 160, 120]               0\n",
      "           Conv2d-30         [-1, 64, 160, 120]          36,864\n",
      "      BatchNorm2d-31         [-1, 64, 160, 120]             128\n",
      "             ReLU-32         [-1, 64, 160, 120]               0\n",
      "           Conv2d-33        [-1, 256, 160, 120]          16,384\n",
      "      BatchNorm2d-34        [-1, 256, 160, 120]             512\n",
      "             ReLU-35        [-1, 256, 160, 120]               0\n",
      "       Bottleneck-36        [-1, 256, 160, 120]               0\n",
      "           Conv2d-37        [-1, 128, 160, 120]          32,768\n",
      "      BatchNorm2d-38        [-1, 128, 160, 120]             256\n",
      "             ReLU-39        [-1, 128, 160, 120]               0\n",
      "           Conv2d-40          [-1, 128, 80, 60]         147,456\n",
      "      BatchNorm2d-41          [-1, 128, 80, 60]             256\n",
      "             ReLU-42          [-1, 128, 80, 60]               0\n",
      "           Conv2d-43          [-1, 512, 80, 60]          65,536\n",
      "      BatchNorm2d-44          [-1, 512, 80, 60]           1,024\n",
      "           Conv2d-45          [-1, 512, 80, 60]         131,072\n",
      "      BatchNorm2d-46          [-1, 512, 80, 60]           1,024\n",
      "             ReLU-47          [-1, 512, 80, 60]               0\n",
      "       Bottleneck-48          [-1, 512, 80, 60]               0\n",
      "           Conv2d-49          [-1, 128, 80, 60]          65,536\n",
      "      BatchNorm2d-50          [-1, 128, 80, 60]             256\n",
      "             ReLU-51          [-1, 128, 80, 60]               0\n",
      "           Conv2d-52          [-1, 128, 80, 60]         147,456\n",
      "      BatchNorm2d-53          [-1, 128, 80, 60]             256\n",
      "             ReLU-54          [-1, 128, 80, 60]               0\n",
      "           Conv2d-55          [-1, 512, 80, 60]          65,536\n",
      "      BatchNorm2d-56          [-1, 512, 80, 60]           1,024\n",
      "             ReLU-57          [-1, 512, 80, 60]               0\n",
      "       Bottleneck-58          [-1, 512, 80, 60]               0\n",
      "           Conv2d-59          [-1, 128, 80, 60]          65,536\n",
      "      BatchNorm2d-60          [-1, 128, 80, 60]             256\n",
      "             ReLU-61          [-1, 128, 80, 60]               0\n",
      "           Conv2d-62          [-1, 128, 80, 60]         147,456\n",
      "      BatchNorm2d-63          [-1, 128, 80, 60]             256\n",
      "             ReLU-64          [-1, 128, 80, 60]               0\n",
      "           Conv2d-65          [-1, 512, 80, 60]          65,536\n",
      "      BatchNorm2d-66          [-1, 512, 80, 60]           1,024\n",
      "             ReLU-67          [-1, 512, 80, 60]               0\n",
      "       Bottleneck-68          [-1, 512, 80, 60]               0\n",
      "           Conv2d-69          [-1, 128, 80, 60]          65,536\n",
      "      BatchNorm2d-70          [-1, 128, 80, 60]             256\n",
      "             ReLU-71          [-1, 128, 80, 60]               0\n",
      "           Conv2d-72          [-1, 128, 80, 60]         147,456\n",
      "      BatchNorm2d-73          [-1, 128, 80, 60]             256\n",
      "             ReLU-74          [-1, 128, 80, 60]               0\n",
      "           Conv2d-75          [-1, 512, 80, 60]          65,536\n",
      "      BatchNorm2d-76          [-1, 512, 80, 60]           1,024\n",
      "             ReLU-77          [-1, 512, 80, 60]               0\n",
      "       Bottleneck-78          [-1, 512, 80, 60]               0\n",
      "           Conv2d-79          [-1, 256, 80, 60]         131,072\n",
      "      BatchNorm2d-80          [-1, 256, 80, 60]             512\n",
      "             ReLU-81          [-1, 256, 80, 60]               0\n",
      "           Conv2d-82          [-1, 256, 80, 60]         589,824\n",
      "      BatchNorm2d-83          [-1, 256, 80, 60]             512\n",
      "             ReLU-84          [-1, 256, 80, 60]               0\n",
      "           Conv2d-85         [-1, 1024, 80, 60]         262,144\n",
      "      BatchNorm2d-86         [-1, 1024, 80, 60]           2,048\n",
      "           Conv2d-87         [-1, 1024, 80, 60]         524,288\n",
      "      BatchNorm2d-88         [-1, 1024, 80, 60]           2,048\n",
      "             ReLU-89         [-1, 1024, 80, 60]               0\n",
      "       Bottleneck-90         [-1, 1024, 80, 60]               0\n",
      "           Conv2d-91          [-1, 256, 80, 60]         262,144\n",
      "      BatchNorm2d-92          [-1, 256, 80, 60]             512\n",
      "             ReLU-93          [-1, 256, 80, 60]               0\n",
      "           Conv2d-94          [-1, 256, 80, 60]         589,824\n",
      "      BatchNorm2d-95          [-1, 256, 80, 60]             512\n",
      "             ReLU-96          [-1, 256, 80, 60]               0\n",
      "           Conv2d-97         [-1, 1024, 80, 60]         262,144\n",
      "      BatchNorm2d-98         [-1, 1024, 80, 60]           2,048\n",
      "             ReLU-99         [-1, 1024, 80, 60]               0\n",
      "      Bottleneck-100         [-1, 1024, 80, 60]               0\n",
      "          Conv2d-101          [-1, 256, 80, 60]         262,144\n",
      "     BatchNorm2d-102          [-1, 256, 80, 60]             512\n",
      "            ReLU-103          [-1, 256, 80, 60]               0\n",
      "          Conv2d-104          [-1, 256, 80, 60]         589,824\n",
      "     BatchNorm2d-105          [-1, 256, 80, 60]             512\n",
      "            ReLU-106          [-1, 256, 80, 60]               0\n",
      "          Conv2d-107         [-1, 1024, 80, 60]         262,144\n",
      "     BatchNorm2d-108         [-1, 1024, 80, 60]           2,048\n",
      "            ReLU-109         [-1, 1024, 80, 60]               0\n",
      "      Bottleneck-110         [-1, 1024, 80, 60]               0\n",
      "          Conv2d-111          [-1, 256, 80, 60]         262,144\n",
      "     BatchNorm2d-112          [-1, 256, 80, 60]             512\n",
      "            ReLU-113          [-1, 256, 80, 60]               0\n",
      "          Conv2d-114          [-1, 256, 80, 60]         589,824\n",
      "     BatchNorm2d-115          [-1, 256, 80, 60]             512\n",
      "            ReLU-116          [-1, 256, 80, 60]               0\n",
      "          Conv2d-117         [-1, 1024, 80, 60]         262,144\n",
      "     BatchNorm2d-118         [-1, 1024, 80, 60]           2,048\n",
      "            ReLU-119         [-1, 1024, 80, 60]               0\n",
      "      Bottleneck-120         [-1, 1024, 80, 60]               0\n",
      "          Conv2d-121          [-1, 256, 80, 60]         262,144\n",
      "     BatchNorm2d-122          [-1, 256, 80, 60]             512\n",
      "            ReLU-123          [-1, 256, 80, 60]               0\n",
      "          Conv2d-124          [-1, 256, 80, 60]         589,824\n",
      "     BatchNorm2d-125          [-1, 256, 80, 60]             512\n",
      "            ReLU-126          [-1, 256, 80, 60]               0\n",
      "          Conv2d-127         [-1, 1024, 80, 60]         262,144\n",
      "     BatchNorm2d-128         [-1, 1024, 80, 60]           2,048\n",
      "            ReLU-129         [-1, 1024, 80, 60]               0\n",
      "      Bottleneck-130         [-1, 1024, 80, 60]               0\n",
      "          Conv2d-131          [-1, 256, 80, 60]         262,144\n",
      "     BatchNorm2d-132          [-1, 256, 80, 60]             512\n",
      "            ReLU-133          [-1, 256, 80, 60]               0\n",
      "          Conv2d-134          [-1, 256, 80, 60]         589,824\n",
      "     BatchNorm2d-135          [-1, 256, 80, 60]             512\n",
      "            ReLU-136          [-1, 256, 80, 60]               0\n",
      "          Conv2d-137         [-1, 1024, 80, 60]         262,144\n",
      "     BatchNorm2d-138         [-1, 1024, 80, 60]           2,048\n",
      "            ReLU-139         [-1, 1024, 80, 60]               0\n",
      "      Bottleneck-140         [-1, 1024, 80, 60]               0\n",
      "          Conv2d-141          [-1, 256, 80, 60]         262,144\n",
      "     BatchNorm2d-142          [-1, 256, 80, 60]             512\n",
      "            ReLU-143          [-1, 256, 80, 60]               0\n",
      "          Conv2d-144          [-1, 256, 80, 60]         589,824\n",
      "     BatchNorm2d-145          [-1, 256, 80, 60]             512\n",
      "            ReLU-146          [-1, 256, 80, 60]               0\n",
      "          Conv2d-147         [-1, 1024, 80, 60]         262,144\n",
      "     BatchNorm2d-148         [-1, 1024, 80, 60]           2,048\n",
      "            ReLU-149         [-1, 1024, 80, 60]               0\n",
      "      Bottleneck-150         [-1, 1024, 80, 60]               0\n",
      "          Conv2d-151          [-1, 256, 80, 60]         262,144\n",
      "     BatchNorm2d-152          [-1, 256, 80, 60]             512\n",
      "            ReLU-153          [-1, 256, 80, 60]               0\n",
      "          Conv2d-154          [-1, 256, 80, 60]         589,824\n",
      "     BatchNorm2d-155          [-1, 256, 80, 60]             512\n",
      "            ReLU-156          [-1, 256, 80, 60]               0\n",
      "          Conv2d-157         [-1, 1024, 80, 60]         262,144\n",
      "     BatchNorm2d-158         [-1, 1024, 80, 60]           2,048\n",
      "            ReLU-159         [-1, 1024, 80, 60]               0\n",
      "      Bottleneck-160         [-1, 1024, 80, 60]               0\n",
      "          Conv2d-161          [-1, 256, 80, 60]         262,144\n",
      "     BatchNorm2d-162          [-1, 256, 80, 60]             512\n",
      "            ReLU-163          [-1, 256, 80, 60]               0\n",
      "          Conv2d-164          [-1, 256, 80, 60]         589,824\n",
      "     BatchNorm2d-165          [-1, 256, 80, 60]             512\n",
      "            ReLU-166          [-1, 256, 80, 60]               0\n",
      "          Conv2d-167         [-1, 1024, 80, 60]         262,144\n",
      "     BatchNorm2d-168         [-1, 1024, 80, 60]           2,048\n",
      "            ReLU-169         [-1, 1024, 80, 60]               0\n",
      "      Bottleneck-170         [-1, 1024, 80, 60]               0\n",
      "          Conv2d-171          [-1, 256, 80, 60]         262,144\n",
      "     BatchNorm2d-172          [-1, 256, 80, 60]             512\n",
      "            ReLU-173          [-1, 256, 80, 60]               0\n",
      "          Conv2d-174          [-1, 256, 80, 60]         589,824\n",
      "     BatchNorm2d-175          [-1, 256, 80, 60]             512\n",
      "            ReLU-176          [-1, 256, 80, 60]               0\n",
      "          Conv2d-177         [-1, 1024, 80, 60]         262,144\n",
      "     BatchNorm2d-178         [-1, 1024, 80, 60]           2,048\n",
      "            ReLU-179         [-1, 1024, 80, 60]               0\n",
      "      Bottleneck-180         [-1, 1024, 80, 60]               0\n",
      "          Conv2d-181          [-1, 256, 80, 60]         262,144\n",
      "     BatchNorm2d-182          [-1, 256, 80, 60]             512\n",
      "            ReLU-183          [-1, 256, 80, 60]               0\n",
      "          Conv2d-184          [-1, 256, 80, 60]         589,824\n",
      "     BatchNorm2d-185          [-1, 256, 80, 60]             512\n",
      "            ReLU-186          [-1, 256, 80, 60]               0\n",
      "          Conv2d-187         [-1, 1024, 80, 60]         262,144\n",
      "     BatchNorm2d-188         [-1, 1024, 80, 60]           2,048\n",
      "            ReLU-189         [-1, 1024, 80, 60]               0\n",
      "      Bottleneck-190         [-1, 1024, 80, 60]               0\n",
      "          Conv2d-191          [-1, 256, 80, 60]         262,144\n",
      "     BatchNorm2d-192          [-1, 256, 80, 60]             512\n",
      "            ReLU-193          [-1, 256, 80, 60]               0\n",
      "          Conv2d-194          [-1, 256, 80, 60]         589,824\n",
      "     BatchNorm2d-195          [-1, 256, 80, 60]             512\n",
      "            ReLU-196          [-1, 256, 80, 60]               0\n",
      "          Conv2d-197         [-1, 1024, 80, 60]         262,144\n",
      "     BatchNorm2d-198         [-1, 1024, 80, 60]           2,048\n",
      "            ReLU-199         [-1, 1024, 80, 60]               0\n",
      "      Bottleneck-200         [-1, 1024, 80, 60]               0\n",
      "          Conv2d-201          [-1, 256, 80, 60]         262,144\n",
      "     BatchNorm2d-202          [-1, 256, 80, 60]             512\n",
      "            ReLU-203          [-1, 256, 80, 60]               0\n",
      "          Conv2d-204          [-1, 256, 80, 60]         589,824\n",
      "     BatchNorm2d-205          [-1, 256, 80, 60]             512\n",
      "            ReLU-206          [-1, 256, 80, 60]               0\n",
      "          Conv2d-207         [-1, 1024, 80, 60]         262,144\n",
      "     BatchNorm2d-208         [-1, 1024, 80, 60]           2,048\n",
      "            ReLU-209         [-1, 1024, 80, 60]               0\n",
      "      Bottleneck-210         [-1, 1024, 80, 60]               0\n",
      "          Conv2d-211          [-1, 256, 80, 60]         262,144\n",
      "     BatchNorm2d-212          [-1, 256, 80, 60]             512\n",
      "            ReLU-213          [-1, 256, 80, 60]               0\n",
      "          Conv2d-214          [-1, 256, 80, 60]         589,824\n",
      "     BatchNorm2d-215          [-1, 256, 80, 60]             512\n",
      "            ReLU-216          [-1, 256, 80, 60]               0\n",
      "          Conv2d-217         [-1, 1024, 80, 60]         262,144\n",
      "     BatchNorm2d-218         [-1, 1024, 80, 60]           2,048\n",
      "            ReLU-219         [-1, 1024, 80, 60]               0\n",
      "      Bottleneck-220         [-1, 1024, 80, 60]               0\n",
      "          Conv2d-221          [-1, 256, 80, 60]         262,144\n",
      "     BatchNorm2d-222          [-1, 256, 80, 60]             512\n",
      "            ReLU-223          [-1, 256, 80, 60]               0\n",
      "          Conv2d-224          [-1, 256, 80, 60]         589,824\n",
      "     BatchNorm2d-225          [-1, 256, 80, 60]             512\n",
      "            ReLU-226          [-1, 256, 80, 60]               0\n",
      "          Conv2d-227         [-1, 1024, 80, 60]         262,144\n",
      "     BatchNorm2d-228         [-1, 1024, 80, 60]           2,048\n",
      "            ReLU-229         [-1, 1024, 80, 60]               0\n",
      "      Bottleneck-230         [-1, 1024, 80, 60]               0\n",
      "          Conv2d-231          [-1, 256, 80, 60]         262,144\n",
      "     BatchNorm2d-232          [-1, 256, 80, 60]             512\n",
      "            ReLU-233          [-1, 256, 80, 60]               0\n",
      "          Conv2d-234          [-1, 256, 80, 60]         589,824\n",
      "     BatchNorm2d-235          [-1, 256, 80, 60]             512\n",
      "            ReLU-236          [-1, 256, 80, 60]               0\n",
      "          Conv2d-237         [-1, 1024, 80, 60]         262,144\n",
      "     BatchNorm2d-238         [-1, 1024, 80, 60]           2,048\n",
      "            ReLU-239         [-1, 1024, 80, 60]               0\n",
      "      Bottleneck-240         [-1, 1024, 80, 60]               0\n",
      "          Conv2d-241          [-1, 256, 80, 60]         262,144\n",
      "     BatchNorm2d-242          [-1, 256, 80, 60]             512\n",
      "            ReLU-243          [-1, 256, 80, 60]               0\n",
      "          Conv2d-244          [-1, 256, 80, 60]         589,824\n",
      "     BatchNorm2d-245          [-1, 256, 80, 60]             512\n",
      "            ReLU-246          [-1, 256, 80, 60]               0\n",
      "          Conv2d-247         [-1, 1024, 80, 60]         262,144\n",
      "     BatchNorm2d-248         [-1, 1024, 80, 60]           2,048\n",
      "            ReLU-249         [-1, 1024, 80, 60]               0\n",
      "      Bottleneck-250         [-1, 1024, 80, 60]               0\n",
      "          Conv2d-251          [-1, 256, 80, 60]         262,144\n",
      "     BatchNorm2d-252          [-1, 256, 80, 60]             512\n",
      "            ReLU-253          [-1, 256, 80, 60]               0\n",
      "          Conv2d-254          [-1, 256, 80, 60]         589,824\n",
      "     BatchNorm2d-255          [-1, 256, 80, 60]             512\n",
      "            ReLU-256          [-1, 256, 80, 60]               0\n",
      "          Conv2d-257         [-1, 1024, 80, 60]         262,144\n",
      "     BatchNorm2d-258         [-1, 1024, 80, 60]           2,048\n",
      "            ReLU-259         [-1, 1024, 80, 60]               0\n",
      "      Bottleneck-260         [-1, 1024, 80, 60]               0\n",
      "          Conv2d-261          [-1, 256, 80, 60]         262,144\n",
      "     BatchNorm2d-262          [-1, 256, 80, 60]             512\n",
      "            ReLU-263          [-1, 256, 80, 60]               0\n",
      "          Conv2d-264          [-1, 256, 80, 60]         589,824\n",
      "     BatchNorm2d-265          [-1, 256, 80, 60]             512\n",
      "            ReLU-266          [-1, 256, 80, 60]               0\n",
      "          Conv2d-267         [-1, 1024, 80, 60]         262,144\n",
      "     BatchNorm2d-268         [-1, 1024, 80, 60]           2,048\n",
      "            ReLU-269         [-1, 1024, 80, 60]               0\n",
      "      Bottleneck-270         [-1, 1024, 80, 60]               0\n",
      "          Conv2d-271          [-1, 256, 80, 60]         262,144\n",
      "     BatchNorm2d-272          [-1, 256, 80, 60]             512\n",
      "            ReLU-273          [-1, 256, 80, 60]               0\n",
      "          Conv2d-274          [-1, 256, 80, 60]         589,824\n",
      "     BatchNorm2d-275          [-1, 256, 80, 60]             512\n",
      "            ReLU-276          [-1, 256, 80, 60]               0\n",
      "          Conv2d-277         [-1, 1024, 80, 60]         262,144\n",
      "     BatchNorm2d-278         [-1, 1024, 80, 60]           2,048\n",
      "            ReLU-279         [-1, 1024, 80, 60]               0\n",
      "      Bottleneck-280         [-1, 1024, 80, 60]               0\n",
      "          Conv2d-281          [-1, 256, 80, 60]         262,144\n",
      "     BatchNorm2d-282          [-1, 256, 80, 60]             512\n",
      "            ReLU-283          [-1, 256, 80, 60]               0\n",
      "          Conv2d-284          [-1, 256, 80, 60]         589,824\n",
      "     BatchNorm2d-285          [-1, 256, 80, 60]             512\n",
      "            ReLU-286          [-1, 256, 80, 60]               0\n",
      "          Conv2d-287         [-1, 1024, 80, 60]         262,144\n",
      "     BatchNorm2d-288         [-1, 1024, 80, 60]           2,048\n",
      "            ReLU-289         [-1, 1024, 80, 60]               0\n",
      "      Bottleneck-290         [-1, 1024, 80, 60]               0\n",
      "          Conv2d-291          [-1, 256, 80, 60]         262,144\n",
      "     BatchNorm2d-292          [-1, 256, 80, 60]             512\n",
      "            ReLU-293          [-1, 256, 80, 60]               0\n",
      "          Conv2d-294          [-1, 256, 80, 60]         589,824\n",
      "     BatchNorm2d-295          [-1, 256, 80, 60]             512\n",
      "            ReLU-296          [-1, 256, 80, 60]               0\n",
      "          Conv2d-297         [-1, 1024, 80, 60]         262,144\n",
      "     BatchNorm2d-298         [-1, 1024, 80, 60]           2,048\n",
      "            ReLU-299         [-1, 1024, 80, 60]               0\n",
      "      Bottleneck-300         [-1, 1024, 80, 60]               0\n",
      "          Conv2d-301          [-1, 256, 80, 60]         262,144\n",
      "     BatchNorm2d-302          [-1, 256, 80, 60]             512\n",
      "            ReLU-303          [-1, 256, 80, 60]               0\n",
      "          Conv2d-304          [-1, 256, 80, 60]         589,824\n",
      "     BatchNorm2d-305          [-1, 256, 80, 60]             512\n",
      "            ReLU-306          [-1, 256, 80, 60]               0\n",
      "          Conv2d-307         [-1, 1024, 80, 60]         262,144\n",
      "     BatchNorm2d-308         [-1, 1024, 80, 60]           2,048\n",
      "            ReLU-309         [-1, 1024, 80, 60]               0\n",
      "      Bottleneck-310         [-1, 1024, 80, 60]               0\n",
      "          Conv2d-311          [-1, 512, 80, 60]         524,288\n",
      "     BatchNorm2d-312          [-1, 512, 80, 60]           1,024\n",
      "            ReLU-313          [-1, 512, 80, 60]               0\n",
      "          Conv2d-314          [-1, 512, 80, 60]       2,359,296\n",
      "     BatchNorm2d-315          [-1, 512, 80, 60]           1,024\n",
      "            ReLU-316          [-1, 512, 80, 60]               0\n",
      "          Conv2d-317         [-1, 2048, 80, 60]       1,048,576\n",
      "     BatchNorm2d-318         [-1, 2048, 80, 60]           4,096\n",
      "          Conv2d-319         [-1, 2048, 80, 60]       2,097,152\n",
      "     BatchNorm2d-320         [-1, 2048, 80, 60]           4,096\n",
      "            ReLU-321         [-1, 2048, 80, 60]               0\n",
      "      Bottleneck-322         [-1, 2048, 80, 60]               0\n",
      "          Conv2d-323          [-1, 512, 80, 60]       1,048,576\n",
      "     BatchNorm2d-324          [-1, 512, 80, 60]           1,024\n",
      "            ReLU-325          [-1, 512, 80, 60]               0\n",
      "          Conv2d-326          [-1, 512, 80, 60]       2,359,296\n",
      "     BatchNorm2d-327          [-1, 512, 80, 60]           1,024\n",
      "            ReLU-328          [-1, 512, 80, 60]               0\n",
      "          Conv2d-329         [-1, 2048, 80, 60]       1,048,576\n",
      "     BatchNorm2d-330         [-1, 2048, 80, 60]           4,096\n",
      "            ReLU-331         [-1, 2048, 80, 60]               0\n",
      "      Bottleneck-332         [-1, 2048, 80, 60]               0\n",
      "          Conv2d-333          [-1, 512, 80, 60]       1,048,576\n",
      "     BatchNorm2d-334          [-1, 512, 80, 60]           1,024\n",
      "            ReLU-335          [-1, 512, 80, 60]               0\n",
      "          Conv2d-336          [-1, 512, 80, 60]       2,359,296\n",
      "     BatchNorm2d-337          [-1, 512, 80, 60]           1,024\n",
      "            ReLU-338          [-1, 512, 80, 60]               0\n",
      "          Conv2d-339         [-1, 2048, 80, 60]       1,048,576\n",
      "     BatchNorm2d-340         [-1, 2048, 80, 60]           4,096\n",
      "            ReLU-341         [-1, 2048, 80, 60]               0\n",
      "      Bottleneck-342         [-1, 2048, 80, 60]               0\n",
      "================================================================\n",
      "Total params: 42,500,160\n",
      "Trainable params: 42,500,160\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 3.52\n",
      "Forward/backward pass size (MB): 7514.06\n",
      "Params size (MB): 162.13\n",
      "Estimated Total Size (MB): 7679.70\n",
      "----------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 256, 80, 60]         524,288\n",
      "       BatchNorm2d-2          [-1, 256, 80, 60]             512\n",
      "              ReLU-3          [-1, 256, 80, 60]               0\n",
      "            Conv2d-4          [-1, 256, 80, 60]       4,718,592\n",
      "       BatchNorm2d-5          [-1, 256, 80, 60]             512\n",
      "              ReLU-6          [-1, 256, 80, 60]               0\n",
      "            Conv2d-7          [-1, 256, 80, 60]       4,718,592\n",
      "       BatchNorm2d-8          [-1, 256, 80, 60]             512\n",
      "              ReLU-9          [-1, 256, 80, 60]               0\n",
      "           Conv2d-10          [-1, 256, 80, 60]       4,718,592\n",
      "      BatchNorm2d-11          [-1, 256, 80, 60]             512\n",
      "             ReLU-12          [-1, 256, 80, 60]               0\n",
      "AdaptiveAvgPool2d-13           [-1, 2048, 1, 1]               0\n",
      "           Conv2d-14            [-1, 256, 1, 1]         524,288\n",
      "      BatchNorm2d-15            [-1, 256, 1, 1]             512\n",
      "             ReLU-16            [-1, 256, 1, 1]               0\n",
      "           Conv2d-17          [-1, 256, 80, 60]         327,680\n",
      "      BatchNorm2d-18          [-1, 256, 80, 60]             512\n",
      "             ReLU-19          [-1, 256, 80, 60]               0\n",
      "          Dropout-20          [-1, 256, 80, 60]               0\n",
      "             ASPP-21          [-1, 256, 80, 60]               0\n",
      "           Conv2d-22          [-1, 256, 80, 60]         589,824\n",
      "      BatchNorm2d-23          [-1, 256, 80, 60]             512\n",
      "             ReLU-24          [-1, 256, 80, 60]               0\n",
      "           Conv2d-25            [-1, 1, 80, 60]             257\n",
      "================================================================\n",
      "Total params: 16,125,697\n",
      "Trainable params: 16,125,697\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 37.50\n",
      "Forward/backward pass size (MB): 187.56\n",
      "Params size (MB): 61.51\n",
      "Estimated Total Size (MB): 286.57\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#**********************************************************************************\n",
    "#Backbone, which should be the extracting feature portion of deeplabv3, and outputs\n",
    "#a [-1, 2048, 80, 60] tensor.\n",
    "\n",
    "#Newly trained classifier takes 2048 cahnnels and out puts 256 channels of 80x60 tensor\n",
    "#How should I upsample it back to 640x480 in order to compare with the labels?\n",
    "#The new classifier used is called Deeplabhead, defined in the following url:\n",
    "#https://github.com/pytorch/vision/blob/master/torchvision/models/segmentation/deeplabv3.py\n",
    "#It seems like the example uses it to replace the classification part of model.\n",
    "#**********************************************************************************\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = createDeepLabv3().to(device)\n",
    "summary(model.backbone, (3, 640, 480))\n",
    "summary(model.classifier, (2048, 80, 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
